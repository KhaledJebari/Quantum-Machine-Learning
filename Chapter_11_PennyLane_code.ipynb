{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398a1114",
   "metadata": {},
   "source": [
    "# CHAPTER 11 - The Best of Both Worlds: Hybrid Architectures - PennyLane Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb727cfc",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This chapter demonstrates **hybrid quantum-classical neural networks** that combine:\n",
    "- **Classical neural network layers** (Dense layers with activation functions)\n",
    "- **Quantum layers** (parameterized quantum circuits)\n",
    "- **Hyperparameter optimization** using Optuna\n",
    "\n",
    "The notebook covers:\n",
    "1. **Binary classification** with a hybrid model (20 → 4 classical → 1 quantum output)\n",
    "2. **Hyperparameter tuning** to find optimal learning rates\n",
    "3. **Multi-class classification** (3 classes) with softmax output\n",
    "\n",
    "**Key adaptations for compatibility:**\n",
    "- Custom `QuantumLayer` class with manual gradient computation (parameter-shift rule)\n",
    "- Custom training loops instead of `model.fit()`\n",
    "- Uses `autograd` interface for quantum circuits (not TensorFlow interface)\n",
    "- Compatible with your existing library versions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f20a9",
   "metadata": {},
   "source": [
    "*Note*: You may skip the following installation cells if you have already installed the right versions of all the libraries mentioned in *Appendix D*. This will likely NOT be the case if you are running this notebook on a cloud service such as Google Colab.\n",
    "\n",
    "**Important - Version Compatibility**: \n",
    "PennyLane 0.26 requires specific versions for compatibility:\n",
    "- **TensorFlow 2.9-2.11** (not 2.12+)\n",
    "- **Keras 2.x (legacy)** via tf-keras package\n",
    "- Using custom quantum layers with manual gradient computation (parameter-shift rule)\n",
    "- **After installing, restart the kernel and run cells in order**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31af5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn>=1.2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8485db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.10.1\n",
      "  Using cached tensorflow-2.10.1-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (25.9.23)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (3.15.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (25.0)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.1)\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl.metadata (806 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (2.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (1.76.0)\n",
      "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.1)\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow==2.10.1) (2.10.0)\n",
      "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.1)\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.41.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.9)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.32.5)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.1)\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.1.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.45.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2025.10.5)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.0.3)\n",
      "Using cached tensorflow-2.10.1-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: keras, tensorboard-data-server, protobuf, tensorboard, tensorflow\n",
      "\n",
      "  Attempting uninstall: keras\n",
      "\n",
      "    Found existing installation: keras 3.12.0\n",
      "\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "    Uninstalling keras-3.12.0:\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "      Successfully uninstalled keras-3.12.0\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "  Attempting uninstall: protobuf\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "    Found existing installation: protobuf 6.33.0\n",
      "   ---------------------------------------- 0/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [protobuf]\n",
      "    Uninstalling protobuf-6.33.0:\n",
      "   ---------------- ----------------------- 2/5 [protobuf]\n",
      "      Successfully uninstalled protobuf-6.33.0\n",
      "   ---------------- ----------------------- 2/5 [protobuf]\n",
      "   ---------------- ----------------------- 2/5 [protobuf]\n",
      "   ---------------- ----------------------- 2/5 [protobuf]\n",
      "  Attempting uninstall: tensorboard\n",
      "   ---------------- ----------------------- 2/5 [protobuf]\n",
      "    Found existing installation: tensorboard 2.20.0\n",
      "   ---------------- ----------------------- 2/5 [protobuf]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "    Uninstalling tensorboard-2.20.0:\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "      Successfully uninstalled tensorboard-2.20.0\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "  Attempting uninstall: tensorflow\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "    Found existing installation: tensorflow 2.20.0\n",
      "   ------------------------ --------------- 3/5 [tensorboard]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "    Uninstalling tensorflow-2.20.0:\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "      Successfully uninstalled tensorflow-2.20.0\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   ---------------------------------------- 5/5 [tensorflow]\n",
      "\n",
      "Successfully installed keras-2.10.0 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.20.1 requires tensorflow<2.21,>=2.20, but you have tensorflow 2.10.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# PennyLane 0.26 works best with TensorFlow 2.10 (most stable version)\n",
    "%pip install \"tensorflow==2.10.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9d0203",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pennylane==0.26 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (0.26.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (1.15.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (3.4.2)\n",
      "Requirement already satisfied: retworkx in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (0.17.1)\n",
      "Requirement already satisfied: autograd in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (1.8.0)\n",
      "Requirement already satisfied: toml in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (0.10.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (1.4.4)\n",
      "Requirement already satisfied: semantic-version>=2.7 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (2.10.0)\n",
      "Requirement already satisfied: autoray>=0.3.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (0.8.0)\n",
      "Requirement already satisfied: cachetools in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (6.2.1)\n",
      "Requirement already satisfied: pennylane-lightning>=0.26 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane==0.26) (0.28.0)\n",
      "Requirement already satisfied: ninja in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from pennylane-lightning>=0.26->pennylane==0.26) (1.13.0)\n",
      "Requirement already satisfied: rustworkx in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from retworkx->pennylane==0.26) (0.17.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install pennylane==0.26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57efa022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib>=3.5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990bdfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna>=3.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f475d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (2.20.1)\n",
      "Collecting tensorflow<2.21,>=2.20 (from tf-keras)\n",
      "  Using cached tensorflow-2.20.0-cp310-cp310-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.4.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.76.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (12.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Using cached tensorflow-2.20.0-cp310-cp310-win_amd64.whl (331.7 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Installing collected packages: tensorboard-data-server, protobuf, tensorboard, keras, tensorflow\n",
      "\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "\n",
      "  Attempting uninstall: protobuf\n",
      "\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "  Attempting uninstall: tensorboard\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "    Found existing installation: tensorboard 2.10.1\n",
      "   -------- ------------------------------- 1/5 [protobuf]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "    Uninstalling tensorboard-2.10.1:\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "      Successfully uninstalled tensorboard-2.10.1\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "  Attempting uninstall: keras\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "    Found existing installation: keras 2.10.0\n",
      "   ---------------- ----------------------- 2/5 [tensorboard]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "    Uninstalling keras-2.10.0:\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "      Successfully uninstalled keras-2.10.0\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "  Attempting uninstall: tensorflow\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "    Found existing installation: tensorflow 2.10.1\n",
      "   ------------------------ --------------- 3/5 [keras]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "    Uninstalling tensorflow-2.10.1:\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "      Successfully uninstalled tensorflow-2.10.1\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   -------------------------------- ------- 4/5 [tensorflow]\n",
      "   ---------------------------------------- 5/5 [tensorflow]\n",
      "\n",
      "Successfully installed keras-3.12.0 protobuf-6.33.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install tf-keras for legacy Keras 2.x support (required for PennyLane 0.26)\n",
    "%pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88850a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for Keras 3.x compatibility with PennyLane 0.26\n",
    "# This must be set BEFORE importing tensorflow\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f228afe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1a344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd3e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf7c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb0c7e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages\\pennylane\\__init__.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "state_0 = [[1], [0]]\n",
    "M = state_0 * np.conj(state_0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0b4a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(history):\n",
    "    tr_loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = np.array(range(len(tr_loss))) + 1\n",
    "    plt.plot(epochs, tr_loss, label = \"Training loss\")\n",
    "    plt.plot(epochs, val_loss, label = \"Validation loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e7edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples = 1000, n_features = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00cdb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_test, y_tr, y_test = train_test_split(\n",
    "    x, y, train_size = 0.8)\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_test, y_test, train_size = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "997e4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoLocal(nqubits, theta, reps = 1):\n",
    "    \n",
    "    for r in range(reps):\n",
    "        for i in range(nqubits):\n",
    "            qml.RY(theta[r * nqubits + i], wires = i)\n",
    "        for i in range(nqubits - 1):\n",
    "            qml.CNOT(wires = [i, i + 1])\n",
    "    \n",
    "    for i in range(nqubits):\n",
    "        qml.RY(theta[reps * nqubits + i], wires = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bd1bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "nqubits = 4\n",
    "dev = qml.device(\"default.qubit\", wires = nqubits)\n",
    "\n",
    "def qnn_circuit(inputs, theta):\n",
    "    qml.AngleEmbedding(inputs, range(nqubits))\n",
    "    TwoLocal(nqubits, theta, reps = 2)\n",
    "    return qml.expval(qml.Hermitian(M, wires = [0]))\n",
    "\n",
    "# Use autograd interface instead of TensorFlow for compatibility\n",
    "qnn = qml.QNode(qnn_circuit, dev, interface=\"autograd\")\n",
    "\n",
    "n_params = 12  # For TwoLocal with reps=2 and 4 qubits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d91d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a custom Keras layer with manual gradient computation\n",
    "class QuantumLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, qnode, n_params, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.qnode = qnode\n",
    "        self.n_params = n_params\n",
    "        self.output_dim = output_dim\n",
    "        # Initialize trainable weights\n",
    "        self.theta = self.add_weight(\n",
    "            name='theta',\n",
    "            shape=(n_params,),\n",
    "            initializer='random_normal',\n",
    "            trainable=True,\n",
    "            dtype=tf.float64\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Get current theta values\n",
    "        theta_np = self.theta.numpy()\n",
    "        \n",
    "        # Convert inputs to numpy if needed\n",
    "        if isinstance(inputs, tf.Tensor):\n",
    "            inputs_np = inputs.numpy()\n",
    "        else:\n",
    "            inputs_np = inputs\n",
    "        \n",
    "        # Forward pass - compute outputs for all samples\n",
    "        outputs = []\n",
    "        for sample in inputs_np:\n",
    "            result = self.qnode(sample, theta_np)\n",
    "            outputs.append(result)\n",
    "        \n",
    "        outputs = np.array(outputs, dtype=np.float64).reshape(-1, self.output_dim)\n",
    "        \n",
    "        # Convert to TensorFlow tensor\n",
    "        return tf.constant(outputs, dtype=tf.float64)\n",
    "    \n",
    "    def compute_gradients(self, inputs, upstream_grad):\n",
    "        \"\"\"Manually compute gradients using parameter-shift rule.\"\"\"\n",
    "        theta_np = self.theta.numpy()\n",
    "        \n",
    "        # Convert inputs to numpy if needed\n",
    "        if isinstance(inputs, tf.Tensor):\n",
    "            inputs_np = inputs.numpy()\n",
    "        else:\n",
    "            inputs_np = inputs\n",
    "        \n",
    "        # Convert upstream_grad to numpy if needed\n",
    "        if isinstance(upstream_grad, tf.Tensor):\n",
    "            upstream_grad_np = upstream_grad.numpy()\n",
    "        else:\n",
    "            upstream_grad_np = upstream_grad\n",
    "        \n",
    "        batch_size = len(inputs_np)\n",
    "        \n",
    "        # Initialize gradient accumulator\n",
    "        total_grad = np.zeros_like(theta_np)\n",
    "        \n",
    "        # Parameter-shift rule: shift = pi/2\n",
    "        shift = np.pi / 2\n",
    "        \n",
    "        # For each sample in the batch\n",
    "        for i, sample in enumerate(inputs_np):\n",
    "            # For each parameter\n",
    "            for j in range(len(theta_np)):\n",
    "                theta_plus = theta_np.copy()\n",
    "                theta_minus = theta_np.copy()\n",
    "                theta_plus[j] += shift\n",
    "                theta_minus[j] -= shift\n",
    "                \n",
    "                # Compute gradient using parameter-shift\n",
    "                grad_j = (self.qnode(sample, theta_plus) - self.qnode(sample, theta_minus)) / 2.0\n",
    "                \n",
    "                # Accumulate gradient weighted by upstream gradient for this sample\n",
    "                if self.output_dim == 1:\n",
    "                    total_grad[j] += upstream_grad_np[i, 0] * grad_j\n",
    "                else:\n",
    "                    # For multi-output, grad_j is an array\n",
    "                    total_grad[j] += np.sum(upstream_grad_np[i] * grad_j)\n",
    "        \n",
    "        return tf.constant(total_grad, dtype=tf.float64)\n",
    "\n",
    "# Create the quantum layer\n",
    "qlayer = QuantumLayer(qnn, n_params=n_params, output_dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d20fc1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid model layers created. Ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Build the hybrid model with classical and quantum layers\n",
    "# Note: We don't use Sequential.build() to avoid graph mode execution\n",
    "classical_layer = tf.keras.layers.Dense(4, activation=\"sigmoid\")\n",
    "\n",
    "# Store references for training\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "\n",
    "print(\"Hybrid model layers created. Ready for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667c81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=2, verbose=1,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b80088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom training functions for hybrid model defined. Ready to train!\n"
     ]
    }
   ],
   "source": [
    "# Custom training functions for hybrid model\n",
    "def train_step_hybrid(x_batch, y_batch):\n",
    "    \"\"\"Perform one training step with manual gradient computation for quantum layer.\"\"\"\n",
    "    # Forward pass through classical layer\n",
    "    classical_output = classical_layer(x_batch)\n",
    "    \n",
    "    # Forward pass through quantum layer\n",
    "    predictions = qlayer(classical_output)\n",
    "    \n",
    "    # Compute loss (binary crossentropy)\n",
    "    epsilon = 1e-7\n",
    "    predictions_clipped = tf.clip_by_value(predictions, epsilon, 1 - epsilon)\n",
    "    loss = -tf.reduce_mean(\n",
    "        y_batch * tf.math.log(predictions_clipped) + \n",
    "        (1 - y_batch) * tf.math.log(1 - predictions_clipped)\n",
    "    )\n",
    "    \n",
    "    # Compute gradients manually\n",
    "    # Gradient of loss w.r.t. predictions\n",
    "    d_loss_d_pred = (predictions_clipped - y_batch.reshape(-1, 1)) / len(y_batch)\n",
    "    \n",
    "    # Get quantum parameter gradients using parameter-shift rule\n",
    "    quantum_grads = qlayer.compute_gradients(classical_output, d_loss_d_pred.numpy())\n",
    "    \n",
    "    # Backpropagate through classical layer using a fresh tape\n",
    "    with tf.GradientTape(persistent=False) as tape:\n",
    "        classical_output_new = classical_layer(x_batch)\n",
    "        # Create a differentiable proxy loss for classical layers\n",
    "        # We approximate by running forward pass again\n",
    "        predictions_new = qlayer(classical_output_new)\n",
    "        predictions_new_clipped = tf.clip_by_value(predictions_new, epsilon, 1 - epsilon)\n",
    "        loss_classical = -tf.reduce_mean(\n",
    "            y_batch * tf.math.log(predictions_new_clipped) + \n",
    "            (1 - y_batch) * tf.math.log(1 - predictions_new_clipped)\n",
    "        )\n",
    "    \n",
    "    # Get gradients for classical layer variables\n",
    "    classical_grads = tape.gradient(loss_classical, classical_layer.trainable_variables)\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer.apply_gradients([(quantum_grads, qlayer.theta)])\n",
    "    if classical_grads[0] is not None:\n",
    "        optimizer.apply_gradients(zip(classical_grads, classical_layer.trainable_variables))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def evaluate_hybrid(x, y):\n",
    "    \"\"\"Evaluate the hybrid model.\"\"\"\n",
    "    classical_output = classical_layer(x)\n",
    "    predictions = qlayer(classical_output)\n",
    "    epsilon = 1e-7\n",
    "    predictions_clipped = tf.clip_by_value(predictions, epsilon, 1 - epsilon)\n",
    "    loss = -tf.reduce_mean(\n",
    "        y * tf.math.log(predictions_clipped) + \n",
    "        (1 - y) * tf.math.log(1 - predictions_clipped)\n",
    "    )\n",
    "    return loss.numpy()\n",
    "\n",
    "def predict_hybrid(x):\n",
    "    \"\"\"Make predictions with the hybrid model.\"\"\"\n",
    "    classical_output = classical_layer(x)\n",
    "    return qlayer(classical_output).numpy()\n",
    "\n",
    "print(\"Custom training functions for hybrid model defined. Ready to train!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4893e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/50 - 173.3s - loss: 1.1776 - val_loss: 0.8284\n",
      "Epoch 1/50 - 173.3s - loss: 1.1776 - val_loss: 0.8284\n",
      "Epoch 2/50 - 269.2s - loss: 0.7241 - val_loss: 0.6997\n",
      "Epoch 2/50 - 269.2s - loss: 0.7241 - val_loss: 0.6997\n",
      "Epoch 3/50 - 318.1s - loss: 0.6941 - val_loss: 0.6989\n",
      "Epoch 3/50 - 318.1s - loss: 0.6941 - val_loss: 0.6989\n",
      "Epoch 4/50 - 324.9s - loss: 0.6975 - val_loss: 0.6985\n",
      "Epoch 4/50 - 324.9s - loss: 0.6975 - val_loss: 0.6985\n",
      "Epoch 5/50 - 356.5s - loss: 0.6952 - val_loss: 0.7013\n",
      "Epoch 5/50 - 356.5s - loss: 0.6952 - val_loss: 0.7013\n",
      "Epoch 6/50 - 367.5s - loss: 0.6959 - val_loss: 0.7022\n",
      "Early stopping at epoch 6\n",
      "Restoring best weights...\n",
      "\n",
      "Training complete!\n",
      "Epoch 6/50 - 367.5s - loss: 0.6959 - val_loss: 0.7022\n",
      "Early stopping at epoch 6\n",
      "Restoring best weights...\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Custom training loop with early stopping\n",
    "import time\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "patience = 2\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_classical_weights = None\n",
    "best_quantum_weights = None\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Shuffle training data\n",
    "    indices = np.random.permutation(len(x_tr))\n",
    "    x_tr_shuffled = x_tr[indices]\n",
    "    y_tr_shuffled = y_tr[indices]\n",
    "    \n",
    "    # Training\n",
    "    epoch_losses = []\n",
    "    num_batches = int(np.ceil(len(x_tr) / batch_size))\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(x_tr))\n",
    "        \n",
    "        x_batch = x_tr_shuffled[start_idx:end_idx]\n",
    "        y_batch = y_tr_shuffled[start_idx:end_idx]\n",
    "        \n",
    "        loss = train_step_hybrid(x_batch, y_batch)\n",
    "        epoch_losses.append(loss.numpy())\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    train_loss = np.mean(epoch_losses)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = evaluate_hybrid(x_val, y_val)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} - {epoch_time:.1f}s - \"\n",
    "          f\"loss: {train_loss:.4f} - val_loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_classical_weights = [w.numpy().copy() for w in classical_layer.trainable_variables]\n",
    "        best_quantum_weights = qlayer.theta.numpy().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            print(\"Restoring best weights...\")\n",
    "            for i, w in enumerate(classical_layer.trainable_variables):\n",
    "                w.assign(best_classical_weights[i])\n",
    "            qlayer.theta.assign(best_quantum_weights)\n",
    "            break\n",
    "\n",
    "# Store history in a similar format to Keras\n",
    "class History:\n",
    "    def __init__(self):\n",
    "        self.history = {\n",
    "            'loss': train_losses,\n",
    "            'val_loss': val_losses\n",
    "        }\n",
    "\n",
    "history = History()\n",
    "print(\"\\nTraining complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd9e17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d5bc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.67625\n",
      "Validation accuracy: 0.69\n",
      "Test accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "tr_acc = accuracy_score(predict_hybrid(x_tr) >= 0.5, y_tr)\n",
    "val_acc = accuracy_score(predict_hybrid(x_val) >= 0.5, y_val)\n",
    "test_acc = accuracy_score(predict_hybrid(x_test) >= 0.5, y_test)\n",
    "print(\"Train accuracy:\", tr_acc)\n",
    "print(\"Validation accuracy:\", val_acc)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6befe3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fe0a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the learning rate as an optimizable parameter\n",
    "    lrate = trial.suggest_float(\"learning_rate\", 0.001, 0.1)\n",
    "    \n",
    "    # Reset the model with new learning rate\n",
    "    global optimizer, classical_layer, qlayer\n",
    "    \n",
    "    # Reinitialize layers\n",
    "    classical_layer = tf.keras.layers.Dense(4, activation=\"sigmoid\")\n",
    "    qlayer = QuantumLayer(qnn, n_params=n_params, output_dim=1)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lrate)\n",
    "    \n",
    "    # Training loop (simplified version)\n",
    "    train_losses_trial = []\n",
    "    val_losses_trial = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_classical_weights = None\n",
    "    best_quantum_weights = None\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        # Shuffle training data\n",
    "        indices = np.random.permutation(len(x_tr))\n",
    "        x_tr_shuffled = x_tr[indices]\n",
    "        y_tr_shuffled = y_tr[indices]\n",
    "        \n",
    "        # Training\n",
    "        epoch_losses = []\n",
    "        num_batches = int(np.ceil(len(x_tr) / 10))\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * 10\n",
    "            end_idx = min(start_idx + 10, len(x_tr))\n",
    "            \n",
    "            x_batch = x_tr_shuffled[start_idx:end_idx]\n",
    "            y_batch = y_tr_shuffled[start_idx:end_idx]\n",
    "            \n",
    "            loss = train_step_hybrid(x_batch, y_batch)\n",
    "            epoch_losses.append(loss.numpy())\n",
    "        \n",
    "        train_loss = np.mean(epoch_losses)\n",
    "        val_loss = evaluate_hybrid(x_val, y_val)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_classical_weights = [w.numpy().copy() for w in classical_layer.trainable_variables]\n",
    "            best_quantum_weights = qlayer.theta.numpy().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 2:\n",
    "                for i, w in enumerate(classical_layer.trainable_variables):\n",
    "                    w.assign(best_classical_weights[i])\n",
    "                qlayer.theta.assign(best_quantum_weights)\n",
    "                break\n",
    "    \n",
    "    # Return the validation accuracy\n",
    "    return accuracy_score(predict_hybrid(x_val) >= 0.5, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e97bdba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 19:08:19,804] A new study created in memory with name: no-name-a5bcb1f3-b854-493a-8095-74bf7435414a\n"
     ]
    }
   ],
   "source": [
    "from optuna.samplers import TPESampler\n",
    "\n",
    "study = optuna.create_study(direction='maximize',\n",
    "    sampler=TPESampler(seed = seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5552e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 19:26:22,068] Trial 0 finished with value: 0.5 and parameters: {'learning_rate': 0.01996042558751034}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-10-28 19:45:48,423] Trial 1 finished with value: 0.64 and parameters: {'learning_rate': 0.06258876833294336}. Best is trial 1 with value: 0.64.\n",
      "[I 2025-10-28 20:15:52,226] Trial 2 finished with value: 0.66 and parameters: {'learning_rate': 0.04433504616170433}. Best is trial 2 with value: 0.66.\n",
      "[I 2025-10-28 20:37:31,736] Trial 3 finished with value: 0.72 and parameters: {'learning_rate': 0.07875049978766316}. Best is trial 3 with value: 0.72.\n",
      "[I 2025-10-28 20:47:47,597] Trial 4 finished with value: 0.57 and parameters: {'learning_rate': 0.07821760500376156}. Best is trial 3 with value: 0.72.\n",
      "[I 2025-10-28 20:51:39,552] Trial 5 finished with value: 0.6 and parameters: {'learning_rate': 0.02798666792298152}. Best is trial 3 with value: 0.72.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5f59f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "699fe339",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples = 1000, n_features = 20,\n",
    "    n_classes = 3, n_clusters_per_class = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce591ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jebar\\miniconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "hot = OneHotEncoder(sparse = False)\n",
    "y_hot = hot.fit_transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a00081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_test, y_tr, y_test = train_test_split(\n",
    "    x, y_hot, train_size = 0.8)\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_test, y_test, train_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "220ec837",
   "metadata": {},
   "outputs": [],
   "source": [
    "nqubits = 4\n",
    "dev_multi = qml.device(\"default.qubit\", wires = nqubits)\n",
    "\n",
    "def qnn_circuit_multi(inputs, theta):\n",
    "    qml.AngleEmbedding(inputs, range(nqubits))\n",
    "    TwoLocal(nqubits, theta, reps = 2)\n",
    "    return [qml.expval(qml.Hermitian(M, wires = [0])),\n",
    "            qml.expval(qml.Hermitian(M, wires = [1])),\n",
    "            qml.expval(qml.Hermitian(M, wires = [2]))]\n",
    "\n",
    "# Use autograd interface instead of TensorFlow for compatibility\n",
    "qnn_multi = qml.QNode(qnn_circuit_multi, dev_multi, interface=\"autograd\")\n",
    "\n",
    "n_params_multi = 12  # For TwoLocal with reps=2 and 4 qubits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb3f328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quantum layer for multi-class classification\n",
    "qlayer_multi = QuantumLayer(qnn_multi, n_params=n_params_multi, output_dim=3)\n",
    "\n",
    "# Build the hybrid model for multi-class\n",
    "dense1 = tf.keras.layers.Dense(8, activation=\"elu\")\n",
    "dense2 = tf.keras.layers.Dense(4, activation=\"sigmoid\")\n",
    "softmax_layer = tf.keras.layers.Activation(activation=\"softmax\")\n",
    "\n",
    "# Store references\n",
    "optimizer_multi = tf.keras.optimizers.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b987312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-class training...\n",
      "Epoch 1/50 - 98.1s - loss: 1.0878 - val_loss: 1.0966\n",
      "Epoch 2/50 - 97.8s - loss: 1.0874 - val_loss: 1.0969\n",
      "Epoch 3/50 - 97.4s - loss: 1.0870 - val_loss: 1.0972\n",
      "Early stopping at epoch 3\n",
      "Restoring best weights...\n",
      "\n",
      "Multi-class training complete!\n"
     ]
    }
   ],
   "source": [
    "# Custom training functions for multi-class classification\n",
    "def forward_multi(x):\n",
    "    \"\"\"Forward pass through the entire multi-class model.\"\"\"\n",
    "    out = dense1(x)\n",
    "    out = dense2(out)\n",
    "    out = qlayer_multi(out)\n",
    "    out = softmax_layer(out)\n",
    "    return out\n",
    "\n",
    "def train_step_multi(x_batch, y_batch):\n",
    "    \"\"\"Training step for multi-class model.\"\"\"\n",
    "    # Forward through classical layers\n",
    "    out1 = dense1(x_batch)\n",
    "    out2 = dense2(out1)\n",
    "    \n",
    "    # Forward through quantum layer\n",
    "    quantum_out = qlayer_multi(out2)\n",
    "    \n",
    "    # Apply softmax\n",
    "    predictions = softmax_layer(quantum_out)\n",
    "    \n",
    "    # Compute loss (categorical crossentropy)\n",
    "    epsilon = 1e-7\n",
    "    predictions_clipped = tf.clip_by_value(predictions, epsilon, 1 - epsilon)\n",
    "    loss = -tf.reduce_mean(tf.reduce_sum(y_batch * tf.math.log(predictions_clipped), axis=1))\n",
    "    \n",
    "    # Compute gradients for quantum layer\n",
    "    # d_loss/d_quantum_out (before softmax)\n",
    "    d_loss_d_quantum = (predictions - y_batch) / len(y_batch)\n",
    "    \n",
    "    # Get quantum parameter gradients\n",
    "    quantum_grads = qlayer_multi.compute_gradients(out2, d_loss_d_quantum.numpy())\n",
    "    \n",
    "    # Backpropagate through classical layers\n",
    "    with tf.GradientTape() as tape:\n",
    "        out1 = dense1(x_batch)\n",
    "        out2 = dense2(out1)\n",
    "        # Use a differentiable loss for classical layers\n",
    "        quantum_out_copy = qlayer_multi(out2)\n",
    "        predictions_copy = softmax_layer(quantum_out_copy)\n",
    "        loss_classical = -tf.reduce_mean(tf.reduce_sum(y_batch * tf.math.log(\n",
    "            tf.clip_by_value(predictions_copy, epsilon, 1 - epsilon)), axis=1))\n",
    "    \n",
    "    # Get classical gradients\n",
    "    classical_vars = dense1.trainable_variables + dense2.trainable_variables\n",
    "    classical_grads = tape.gradient(loss_classical, classical_vars)\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer_multi.apply_gradients([(quantum_grads, qlayer_multi.theta)])\n",
    "    if classical_grads[0] is not None:\n",
    "        optimizer_multi.apply_gradients(zip(classical_grads, classical_vars))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def evaluate_multi(x, y):\n",
    "    \"\"\"Evaluate multi-class model.\"\"\"\n",
    "    predictions = forward_multi(x)\n",
    "    epsilon = 1e-7\n",
    "    predictions_clipped = tf.clip_by_value(predictions, epsilon, 1 - epsilon)\n",
    "    loss = -tf.reduce_mean(tf.reduce_sum(y * tf.math.log(predictions_clipped), axis=1))\n",
    "    return loss.numpy()\n",
    "\n",
    "# Training loop for multi-class\n",
    "import time\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 50\n",
    "patience = 2\n",
    "\n",
    "train_losses_multi = []\n",
    "val_losses_multi = []\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_weights = {}\n",
    "\n",
    "print(\"Starting multi-class training...\")\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Shuffle training data\n",
    "    indices = np.random.permutation(len(x_tr))\n",
    "    x_tr_shuffled = x_tr[indices]\n",
    "    y_tr_shuffled = y_tr[indices]\n",
    "    \n",
    "    # Training\n",
    "    epoch_losses = []\n",
    "    num_batches = int(np.ceil(len(x_tr) / batch_size))\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(x_tr))\n",
    "        \n",
    "        x_batch = x_tr_shuffled[start_idx:end_idx]\n",
    "        y_batch = y_tr_shuffled[start_idx:end_idx]\n",
    "        \n",
    "        loss = train_step_multi(x_batch, y_batch)\n",
    "        epoch_losses.append(loss.numpy())\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    train_loss = np.mean(epoch_losses)\n",
    "    train_losses_multi.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = evaluate_multi(x_val, y_val)\n",
    "    val_losses_multi.append(val_loss)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} - {epoch_time:.1f}s - \"\n",
    "          f\"loss: {train_loss:.4f} - val_loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_weights['dense1'] = [w.numpy().copy() for w in dense1.trainable_variables]\n",
    "        best_weights['dense2'] = [w.numpy().copy() for w in dense2.trainable_variables]\n",
    "        best_weights['quantum'] = qlayer_multi.theta.numpy().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            print(\"Restoring best weights...\")\n",
    "            for i, w in enumerate(dense1.trainable_variables):\n",
    "                w.assign(best_weights['dense1'][i])\n",
    "            for i, w in enumerate(dense2.trainable_variables):\n",
    "                w.assign(best_weights['dense2'][i])\n",
    "            qlayer_multi.theta.assign(best_weights['quantum'])\n",
    "            break\n",
    "\n",
    "# Store history\n",
    "class HistoryMulti:\n",
    "    def __init__(self):\n",
    "        self.history = {\n",
    "            'loss': train_losses_multi,\n",
    "            'val_loss': val_losses_multi\n",
    "        }\n",
    "\n",
    "history = HistoryMulti()\n",
    "print(\"\\nMulti-class training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b06a871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "731bfaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4125\n",
      "Validation accuracy: 0.31\n",
      "Test accuracy: 0.36\n"
     ]
    }
   ],
   "source": [
    "tr_acc = accuracy_score(\n",
    "    forward_multi(x_tr).numpy().argmax(axis=1),\n",
    "    y_tr.argmax(axis=1))\n",
    "val_acc = accuracy_score(\n",
    "    forward_multi(x_val).numpy().argmax(axis=1),\n",
    "    y_val.argmax(axis=1))\n",
    "test_acc = accuracy_score(\n",
    "    forward_multi(x_test).numpy().argmax(axis=1),\n",
    "    y_test.argmax(axis=1))\n",
    "print(\"Train accuracy:\", tr_acc)\n",
    "print(\"Validation accuracy:\", val_acc)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f04f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
